{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Emotion Recognition\n",
    "\n",
    "Author: Faizan Khan\n",
    "\n",
    "Date: 26th June 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 22:42:40,111 - modelscope - WARNING - Model revision not specified, use revision: v2.0.5\n",
      "2024-06-26 22:42:40,552 - modelscope - INFO - initiate model from /Users/faizankhan/.cache/modelscope/hub/iic/emotion2vec_plus_large\n",
      "2024-06-26 22:42:40,553 - modelscope - INFO - initiate model from location /Users/faizankhan/.cache/modelscope/hub/iic/emotion2vec_plus_large.\n",
      "2024-06-26 22:42:40,556 - modelscope - INFO - initialize model from /Users/faizankhan/.cache/modelscope/hub/iic/emotion2vec_plus_large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect model requirements, begin to install it: /Users/faizankhan/.cache/modelscope/hub/iic/emotion2vec_plus_large/requirements.txt\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "install model requirements successfully\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.0.0.weight, /Users/faizankhan/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.0.0.bias, /Users/faizankhan/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.1.0.weight, /Users/faizankhan/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.1.0.bias, /Users/faizankhan/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.2.0.weight, /Users/faizankhan/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.2.0.bias, /Users/faizankhan/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.3.0.weight, /Users/faizankhan/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.3.0.bias, /Users/faizankhan/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.proj.weight, /Users/faizankhan/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.proj.bias, /Users/faizankhan/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 22:42:44,764 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-26 22:42:44,764 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-26 22:42:44,765 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/Users/faizankhan/.cache/modelscope/hub/iic/emotion2vec_plus_large'}. trying to build by task and model information.\n",
      "2024-06-26 22:42:44,765 - modelscope - WARNING - No preprocessor key ('funasr', 'emotion-recognition') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2024-06-26 22:42:44,767 - modelscope - INFO - cuda is not available, using cpu instead.\n",
      "rtf_avg: 0.052: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  5.21it/s]                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': '03-01-03-02-01-01-01', 'labels': ['生气/angry', '开心/happy', '中立/neutral', '难过/sad', '<unk>'], 'scores': [4.931269281804873e-11, 1.0, 4.515554163225799e-12, 9.499289549408374e-11, 2.1678057309053165e-16]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "\n",
    "inference_pipeline = pipeline(\n",
    "    task=Tasks.emotion_recognition,\n",
    "    model=\"iic/emotion2vec_plus_large\")\n",
    "\n",
    "rec_result = inference_pipeline('03-01-03-02-01-01-01.wav', granularity=\"utterance\", extract_embedding=False)\n",
    "print(rec_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Emotion Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8626f06d5a044379ba384dc0b2e1b61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be85c556cb2346a18a49aeb41834308e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ffd239fa194f12ad5b73b8deb168c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/294 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38cf0569b4664da6b2a35739c99a5cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d142dd5d5a044724b15a378659c9a658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff76e5a26568465185eb3a77836f3c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8721b3953fb1468493e461cfc160c036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faizankhan/Library/Python/3.9/lib/python/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'anger', 'score': 0.0044197943061590195},\n",
       "  {'label': 'disgust', 'score': 0.0016119939973577857},\n",
       "  {'label': 'fear', 'score': 0.00041385297663509846},\n",
       "  {'label': 'joy', 'score': 0.9771687984466553},\n",
       "  {'label': 'neutral', 'score': 0.005764588713645935},\n",
       "  {'label': 'sadness', 'score': 0.002092392183840275},\n",
       "  {'label': 'surprise', 'score': 0.008528684265911579}]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "classifier(\"I love this!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faizankhan/Library/Python/3.9/lib/python/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " Kids are talking by the door.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model_stt = whisper.load_model(\"base\")\n",
    "result = model_stt.transcribe(\"03-01-03-02-01-01-01.wav\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech + Text Emotion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faizankhan/Library/Python/3.9/lib/python/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.105: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.58it/s]                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': '03-01-03-02-01-01-01', 'labels': ['生气/angry', '开心/happy', '中立/neutral', '难过/sad', '<unk>'], 'scores': [4.931269281804873e-11, 1.0, 4.515554163225799e-12, 9.499289549408374e-11, 2.1678057309053165e-16]}]\n",
      "[[{'label': 'anger', 'score': 0.026580234989523888}, {'label': 'disgust', 'score': 0.1816110759973526}, {'label': 'fear', 'score': 0.019398074597120285}, {'label': 'joy', 'score': 0.0063143325969576836}, {'label': 'neutral', 'score': 0.7140928506851196}, {'label': 'sadness', 'score': 0.006463354453444481}, {'label': 'surprise', 'score': 0.04554012417793274}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = model_stt.transcribe(\"03-01-03-02-01-01-01.wav\")\n",
    "transcribed_text = result['text']\n",
    "\n",
    "speech_emotion = inference_pipeline('03-01-03-02-01-01-01.wav', granularity=\"utterance\", extract_embedding=False)\n",
    "print(speech_emotion)\n",
    "\n",
    "text_emotion = classifier(transcribed_text)\n",
    "print(text_emotion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
